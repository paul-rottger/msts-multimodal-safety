{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = 'data/response_annotations/' \n",
    "pth = f'{dir_}english_multimodal_unsafe.csv'\n",
    "df = pd.read_csv(pth)[['final_label', 'llavaguard']]\n",
    "df = df.rename(columns={'final_label': 'human'})\n",
    "\n",
    "for root, dirs, files in os.walk(dir_):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\") and \"unsafe\" not in file and \"detailed\" not in file and \"autoeval\" not in file:\n",
    "            # print(file)\n",
    "            model_name = file.split('_')[2].split('.csv')[0]\n",
    "            if \"gpt\" in model_name:\n",
    "                df_ = pd.read_csv(f'{dir_}{file}', names=[\"GPT4\"])\n",
    "                df_ = df_.reindex(df.index).reset_index(drop=True)\n",
    "            else:    \n",
    "                df_ = pd.read_csv(f'{dir_}{file}')\n",
    "            \n",
    "            if \"GPT4\" in df_.columns:\n",
    "                key = \"GPT4\"\n",
    "            elif \"vlm_sglang\" in df_.columns:\n",
    "                key = \"vlm_sglang\"\n",
    "            \n",
    "            df_ = df_[[key]]\n",
    "            # rename column key to model\n",
    "            df_ = df_.rename(columns={key: model_name})\n",
    "            df = pd.concat([df, df_], axis=1)\n",
    "df.to_csv(f'{dir_}english_multimodal_autoeval.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{dir_}english_multimodal_autoeval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{dir_}english_multimodal_autoeval.csv')\n",
    "df['human'] = df['human'].apply(lambda x: 2 if \"unsafe\" in x.lower() else 1 if \"safe\" in x.lower() else np.NaN)\n",
    "df['llavaguard'] = df['llavaguard'].apply(lambda x: 2 if \"unsafe\" in x.lower() else 1 if \"safe\" in x.lower() else np.NaN)\n",
    "df['omni-moderation-latest'] = df['omni-moderation-latest'].apply(lambda x: 2 if x else 1 if x==False else np.NaN)\n",
    "df['Qwen2-Vl-72b-Instruct'] = df['Qwen2-Vl-72b-Instruct'].apply(lambda x: 2 if \"unsafe\" in x.lower() else 1 if \"safe\" in x.lower() else np.NaN)\n",
    "df['llava-onevision-qwen2-72b-ov-sft'] = df['llava-onevision-qwen2-72b-ov-sft'].apply(lambda x: 2 if \"unsafe\" in x.lower() else 1 if \"safe\" in x.lower() else np.NaN)\n",
    "df['Llama-3.2-90B-Vision-Instruct'] = df['Llama-3.2-90B-Vision-Instruct'].apply(lambda x: 2 if \"unsafe\" in x.lower() else 1 if \"safe\" in x.lower() else np.NaN)\n",
    "\n",
    "def replace_val(x):\n",
    "    # check if x is nan\n",
    "    if pd.isna(x):\n",
    "        return np.NaN\n",
    "    elif \"unsafe\" in x.lower():\n",
    "        return 2\n",
    "    elif \"safe\" in x.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "df['gpt-4-turbo-2024-04-09'] = df['gpt-4-turbo-2024-04-09'].apply(replace_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llavaguard\n",
      "invalid ratio: 0.29975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.51      0.66      2707\n",
      "           2       0.02      0.28      0.04        94\n",
      "\n",
      "    accuracy                           0.50      2801\n",
      "   macro avg       0.49      0.39      0.35      2801\n",
      "weighted avg       0.92      0.50      0.64      2801\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "omni-moderation-latest\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.81      0.87      3819\n",
      "           2       0.03      0.10      0.04       181\n",
      "\n",
      "    accuracy                           0.78      4000\n",
      "   macro avg       0.49      0.46      0.46      4000\n",
      "weighted avg       0.91      0.78      0.84      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Qwen2-Vl-72b-Instruct\n",
      "invalid ratio: 0.00025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.97      0.97      3818\n",
      "           2       0.13      0.08      0.10       181\n",
      "\n",
      "    accuracy                           0.93      3999\n",
      "   macro avg       0.55      0.53      0.53      3999\n",
      "weighted avg       0.92      0.93      0.93      3999\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "llava-onevision-qwen2-72b-ov-sft\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96      3819\n",
      "           2       0.12      0.12      0.12       181\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.54      0.54      0.54      4000\n",
      "weighted avg       0.92      0.92      0.92      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Llama-3.2-90B-Vision-Instruct\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.58      0.72      3819\n",
      "           2       0.02      0.20      0.04       181\n",
      "\n",
      "    accuracy                           0.56      4000\n",
      "   macro avg       0.48      0.39      0.38      4000\n",
      "weighted avg       0.90      0.56      0.69      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gpt-4-turbo-2024-04-09\n",
      "invalid ratio: 0.3515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.99      0.97      2465\n",
      "           2       0.06      0.01      0.01       129\n",
      "\n",
      "    accuracy                           0.94      2594\n",
      "   macro avg       0.50      0.50      0.49      2594\n",
      "weighted avg       0.91      0.94      0.92      2594\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compare each column with the first column (human) in terms of classification report\n",
    "for col in df.columns[1:]:\n",
    "    print(col)\n",
    "    # for classification report, we need to ignore the NaN values\n",
    "    nans = df[col].isna()\n",
    "    print(f\"invalid ratio: {nans.sum() / len(df)}\")\n",
    "    report = classification_report(df['human'][~nans], df[col][~nans], zero_division=0)\n",
    "    print(report)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
