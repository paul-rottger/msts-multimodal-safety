{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_val(x):\n",
    "    # check if x is nan\n",
    "    if pd.isna(x):\n",
    "        return np.NaN\n",
    "    elif \"unsafe\" in x.lower():\n",
    "        return 2\n",
    "    elif \"safe\" in x.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-Guard-3-11B-Vision\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.99      0.98      3819\n",
      "           2       0.55      0.20      0.30       181\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.76      0.60      0.64      4000\n",
      "weighted avg       0.94      0.96      0.95      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LlavaGuard-v1.2-7B-OV\n",
      "invalid ratio: 0.0005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.97      0.96      3817\n",
      "           2       0.07      0.05      0.06       181\n",
      "\n",
      "    accuracy                           0.92      3998\n",
      "   macro avg       0.51      0.51      0.51      3998\n",
      "weighted avg       0.92      0.92      0.92      3998\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Llama-3.2-90B-Vision-Instruct\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.99      0.98      3819\n",
      "           2       0.57      0.20      0.30       181\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.77      0.60      0.64      4000\n",
      "weighted avg       0.95      0.96      0.95      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "omni-moderation-latest\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.81      0.87      3819\n",
      "           2       0.03      0.10      0.04       181\n",
      "\n",
      "    accuracy                           0.78      4000\n",
      "   macro avg       0.49      0.46      0.46      4000\n",
      "weighted avg       0.91      0.78      0.84      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gpt-4o-2024-05-13\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.82      0.90      3819\n",
      "           2       0.19      0.91      0.31       181\n",
      "\n",
      "    accuracy                           0.82      4000\n",
      "   macro avg       0.59      0.86      0.60      4000\n",
      "weighted avg       0.96      0.82      0.87      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gemini-1.5-pro\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.97      0.98      3819\n",
      "           2       0.53      0.68      0.59       181\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.76      0.83      0.79      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "claude-3-5-sonnet-20240620\n",
      "invalid ratio: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.98      0.98      3819\n",
      "           2       0.52      0.52      0.52       181\n",
      "\n",
      "    accuracy                           0.96      4000\n",
      "   macro avg       0.75      0.75      0.75      4000\n",
      "weighted avg       0.96      0.96      0.96      4000\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_ = 'data/auto_eval/' \n",
    "pth_gen = f'data/auto_eval/english_multimodal_autoeval.csv'\n",
    "pth_gt = f'data/response_annotations/english_multimodal.csv'\n",
    "\n",
    "df = pd.read_csv(pth_gen)\n",
    "df_gt = pd.read_csv(pth_gt)['final_label'].apply(replace_val)\n",
    "\n",
    "# compare each column with gt in terms of classification report\n",
    "for col in df.columns[1:]:\n",
    "    print(col)\n",
    "    df[col] = df[col].apply(replace_val)\n",
    "    # for classification report, we need to ignore the NaN values\n",
    "    nans = df[col].isna()\n",
    "    print(f\"invalid ratio: {nans.sum() / len(df)}\")\n",
    "    report = classification_report(df_gt[~nans], df[col][~nans], zero_division=0)\n",
    "    print(report)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
